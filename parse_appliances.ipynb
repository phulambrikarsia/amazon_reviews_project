{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8013bd9c-cda7-4f5d-ab10-afa841ae729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory named 'data' in the current working directory\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "# URL of the JSON file containing the Appliances data\n",
    "appliances_url = \"https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/Appliances.json.gz\"\n",
    "\n",
    "# Local file path to save the downloaded JSON file\n",
    "local_json_file_path = \"data/appliances.json\"\n",
    "\n",
    "# Check if the JSON file already exists to avoid re-downloading it\n",
    "if not os.path.exists(local_json_file_path):\n",
    "    # Send a GET request to the URL and save the content to the local .json file\n",
    "    response = requests.get(appliances_url)\n",
    "    with open(local_json_file_path, 'wb') as file:\n",
    "        file.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# URL of the JSON file containing the metadata for Appliances\n",
    "meta_url = \"https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/metaFiles2/meta_Appliances.json.gz\"\n",
    "\n",
    "# Local file path to save the downloaded JSON file\n",
    "local_meta_file_path = \"data/meta_appliances.json\"\n",
    "\n",
    "# Check if the JSON file already exists to avoid re-downloading it\n",
    "if not os.path.exists(local_meta_file_path):\n",
    "    # Send a GET request to the URL and save the content to the local .json file\n",
    "    response = requests.get(meta_url)\n",
    "    with open(local_meta_file_path, 'wb') as file:\n",
    "        file.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "727f4acd-c67e-4351-9036-de328e945129",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File /Users/sia/Library/CloudStorage/OneDrive-UCLAITServices/Data Blog/Fall 23/Appliances_5.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/monkeypunkey/Personal/projects/school/amazon_reviews_project/parse_appliances.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/monkeypunkey/Personal/projects/school/amazon_reviews_project/parse_appliances.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m appliances_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/sia/Library/CloudStorage/OneDrive-UCLAITServices/Data Blog/Fall 23/Appliances_5.json\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/monkeypunkey/Personal/projects/school/amazon_reviews_project/parse_appliances.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m meta_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/sia/Library/CloudStorage/OneDrive-UCLAITServices/Data Blog/Fall 23/meta_Appliances.json\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/monkeypunkey/Personal/projects/school/amazon_reviews_project/parse_appliances.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m appliances \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(appliances_path, lines \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/monkeypunkey/Personal/projects/school/amazon_reviews_project/parse_appliances.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m appliances_meta \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_json(meta_path, lines \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_json.py:780\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mif\u001b[39;00m convert_axes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m orient \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    778\u001b[0m     convert_axes \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 780\u001b[0m json_reader \u001b[39m=\u001b[39m JsonReader(\n\u001b[1;32m    781\u001b[0m     path_or_buf,\n\u001b[1;32m    782\u001b[0m     orient\u001b[39m=\u001b[39;49morient,\n\u001b[1;32m    783\u001b[0m     typ\u001b[39m=\u001b[39;49mtyp,\n\u001b[1;32m    784\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    785\u001b[0m     convert_axes\u001b[39m=\u001b[39;49mconvert_axes,\n\u001b[1;32m    786\u001b[0m     convert_dates\u001b[39m=\u001b[39;49mconvert_dates,\n\u001b[1;32m    787\u001b[0m     keep_default_dates\u001b[39m=\u001b[39;49mkeep_default_dates,\n\u001b[1;32m    788\u001b[0m     precise_float\u001b[39m=\u001b[39;49mprecise_float,\n\u001b[1;32m    789\u001b[0m     date_unit\u001b[39m=\u001b[39;49mdate_unit,\n\u001b[1;32m    790\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    791\u001b[0m     lines\u001b[39m=\u001b[39;49mlines,\n\u001b[1;32m    792\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    793\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    794\u001b[0m     nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[1;32m    795\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    796\u001b[0m     encoding_errors\u001b[39m=\u001b[39;49mencoding_errors,\n\u001b[1;32m    797\u001b[0m     dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[1;32m    798\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    799\u001b[0m )\n\u001b[1;32m    801\u001b[0m \u001b[39mif\u001b[39;00m chunksize:\n\u001b[1;32m    802\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_json.py:893\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m filepath_or_buffer\n\u001b[1;32m    892\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mujson\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 893\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data_from_filepath(filepath_or_buffer)\n\u001b[1;32m    894\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_json.py:949\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    941\u001b[0m     filepath_or_buffer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n\u001b[1;32m    942\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m    943\u001b[0m     \u001b[39misinstance\u001b[39m(filepath_or_buffer, \u001b[39mstr\u001b[39m)\n\u001b[1;32m    944\u001b[0m     \u001b[39mand\u001b[39;00m filepath_or_buffer\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mendswith(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    948\u001b[0m ):\n\u001b[0;32m--> 949\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00mfilepath_or_buffer\u001b[39m}\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    950\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    951\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    952\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing literal json to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mread_json\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. To read from a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    957\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File /Users/sia/Library/CloudStorage/OneDrive-UCLAITServices/Data Blog/Fall 23/Appliances_5.json does not exist"
     ]
    }
   ],
   "source": [
    "appliances_path = '/Users/sia/Library/CloudStorage/OneDrive-UCLAITServices/Data Blog/Fall 23/Appliances_5.json'\n",
    "meta_path = '/Users/sia/Library/CloudStorage/OneDrive-UCLAITServices/Data Blog/Fall 23/meta_Appliances.json'\n",
    "appliances = pd.read_json(appliances_path, lines = True)\n",
    "appliances_meta = pd.read_json(meta_path, lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43349e09-f55d-47d1-9f1e-b6c57d50c893",
   "metadata": {},
   "source": [
    "### Description of our Data\n",
    "\n",
    "`appliances`: pandas dataframe containing 5-core subsets of Amazon reviews related to Appliances, (all users and items have at least 5 reviews)\n",
    "`appliances_meta`: pandas dataframe containing metadata related to products and product categories, including price and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4875e7d-5f66-4979-b425-e6fff88f0745",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "appliances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c141cc03-9b36-4a63-bb2c-ddf0ea14d396",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "appliances_meta.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
